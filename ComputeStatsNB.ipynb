{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c185b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cProfile as profile\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "\n",
    "from metrics.stats_utils import (\n",
    "    get_dice_1,\n",
    "    get_fast_aji,\n",
    "    get_fast_aji_plus,\n",
    "    get_fast_dice_2,\n",
    "    get_fast_pq,\n",
    "    remap_label,\n",
    "    pair_coordinates\n",
    ")\n",
    "\n",
    "\n",
    "def run_nuclei_type_stat(pred_dir, true_dir, type_uid_list=None, exhaustive=True):\n",
    "    \"\"\"GT must be exhaustively annotated for instance location (detection).\n",
    "\n",
    "    Args:\n",
    "        true_dir, pred_dir: Directory contains .mat annotation for each image. \n",
    "                            Each .mat must contain:\n",
    "                    --`inst_centroid`: Nx2, contains N instance centroid\n",
    "                                       of mass coordinates (X, Y)\n",
    "                    --`inst_type`    : Nx1: type of each instance at each index\n",
    "                    `inst_centroid` and `inst_type` must be aligned and each\n",
    "                    index must be associated to the same instance\n",
    "        type_uid_list : list of id for nuclei type which the score should be calculated.\n",
    "                        Default to `None` means available nuclei type in GT.\n",
    "        exhaustive : Flag to indicate whether GT is exhaustively labelled\n",
    "                     for instance types\n",
    "                     \n",
    "    \"\"\"\n",
    "    file_list = glob.glob(pred_dir + \"*.mat\")\n",
    "    file_list.sort()  # ensure same order [1]\n",
    "\n",
    "    paired_all = []  # unique matched index pair\n",
    "    unpaired_true_all = []  # the index must exist in `true_inst_type_all` and unique\n",
    "    unpaired_pred_all = []  # the index must exist in `pred_inst_type_all` and unique\n",
    "    true_inst_type_all = []  # each index is 1 independent data point\n",
    "    pred_inst_type_all = []  # each index is 1 independent data point\n",
    "    for file_idx, filename in enumerate(file_list[:]):\n",
    "        filename = os.path.basename(filename)\n",
    "        basename = filename.split(\".\")[0]\n",
    "\n",
    "        true_info = sio.loadmat(os.path.join(true_dir, basename + \".mat\"))\n",
    "        # dont squeeze, may be 1 instance exist\n",
    "        true_centroid = (true_info[\"inst_centroid\"]).astype(\"float32\")\n",
    "        true_inst_type = (true_info[\"inst_type\"]).astype(\"int32\")\n",
    "\n",
    "        if true_centroid.shape[0] != 0:\n",
    "            true_inst_type = true_inst_type[:, 0]\n",
    "        else:  # no instance at all\n",
    "            true_centroid = np.array([[0, 0]])\n",
    "            true_inst_type = np.array([0])\n",
    "\n",
    "        # * for converting the GT type in CoNSeP\n",
    "        # true_inst_type[(true_inst_type == 3) | (true_inst_type == 4)] = 3\n",
    "        # true_inst_type[(true_inst_type == 5) | (true_inst_type == 6) | (true_inst_type == 7)] = 4\n",
    "\n",
    "        pred_info = sio.loadmat(os.path.join(pred_dir, basename + \".mat\"))\n",
    "        # dont squeeze, may be 1 instance exist\n",
    "        pred_centroid = (pred_info[\"inst_centroid\"]).astype(\"float32\")\n",
    "        pred_inst_type = (pred_info[\"inst_type\"]).astype(\"int32\")\n",
    "\n",
    "        if pred_centroid.shape[0] != 0:\n",
    "            pred_inst_type = pred_inst_type[:, 0]\n",
    "        else:  # no instance at all\n",
    "            pred_centroid = np.array([[0, 0]])\n",
    "            pred_inst_type = np.array([0])\n",
    "\n",
    "        # ! if take longer than 1min for 1000 vs 1000 pairing, sthg is wrong with coord\n",
    "        paired, unpaired_true, unpaired_pred = pair_coordinates(\n",
    "            true_centroid, pred_centroid, 12\n",
    "        )\n",
    "\n",
    "        # * Aggreate information\n",
    "        # get the offset as each index represent 1 independent instance\n",
    "        true_idx_offset = (\n",
    "            true_idx_offset + true_inst_type_all[-1].shape[0] if file_idx != 0 else 0\n",
    "        )\n",
    "        pred_idx_offset = (\n",
    "            pred_idx_offset + pred_inst_type_all[-1].shape[0] if file_idx != 0 else 0\n",
    "        )\n",
    "        true_inst_type_all.append(true_inst_type)\n",
    "        pred_inst_type_all.append(pred_inst_type)\n",
    "\n",
    "        # increment the pairing index statistic\n",
    "        if paired.shape[0] != 0:  # ! sanity\n",
    "            paired[:, 0] += true_idx_offset\n",
    "            paired[:, 1] += pred_idx_offset\n",
    "            paired_all.append(paired)\n",
    "\n",
    "        unpaired_true += true_idx_offset\n",
    "        unpaired_pred += pred_idx_offset\n",
    "        unpaired_true_all.append(unpaired_true)\n",
    "        unpaired_pred_all.append(unpaired_pred)\n",
    "\n",
    "    paired_all = np.concatenate(paired_all, axis=0)\n",
    "    unpaired_true_all = np.concatenate(unpaired_true_all, axis=0)\n",
    "    unpaired_pred_all = np.concatenate(unpaired_pred_all, axis=0)\n",
    "    true_inst_type_all = np.concatenate(true_inst_type_all, axis=0)\n",
    "    pred_inst_type_all = np.concatenate(pred_inst_type_all, axis=0)\n",
    "\n",
    "    paired_true_type = true_inst_type_all[paired_all[:, 0]]\n",
    "    paired_pred_type = pred_inst_type_all[paired_all[:, 1]]\n",
    "    unpaired_true_type = true_inst_type_all[unpaired_true_all]\n",
    "    unpaired_pred_type = pred_inst_type_all[unpaired_pred_all]\n",
    "\n",
    "    ###\n",
    "    def _f1_type(paired_true, paired_pred, unpaired_true, unpaired_pred, type_id, w):\n",
    "        type_samples = (paired_true == type_id) | (paired_pred == type_id)\n",
    "\n",
    "        paired_true = paired_true[type_samples]\n",
    "        paired_pred = paired_pred[type_samples]\n",
    "\n",
    "        tp_dt = ((paired_true == type_id) & (paired_pred == type_id)).sum()\n",
    "        tn_dt = ((paired_true != type_id) & (paired_pred != type_id)).sum()\n",
    "        fp_dt = ((paired_true != type_id) & (paired_pred == type_id)).sum()\n",
    "        fn_dt = ((paired_true == type_id) & (paired_pred != type_id)).sum()\n",
    "\n",
    "        if not exhaustive:\n",
    "            ignore = (paired_true == -1).sum()\n",
    "            fp_dt -= ignore\n",
    "\n",
    "        fp_d = (unpaired_pred == type_id).sum()\n",
    "        fn_d = (unpaired_true == type_id).sum()\n",
    "\n",
    "        f1_type = (2 * (tp_dt + tn_dt)) / (\n",
    "            2 * (tp_dt + tn_dt)\n",
    "            + w[0] * fp_dt\n",
    "            + w[1] * fn_dt\n",
    "            + w[2] * fp_d\n",
    "            + w[3] * fn_d\n",
    "        )\n",
    "        return f1_type\n",
    "\n",
    "    # overall\n",
    "    # * quite meaningless for not exhaustive annotated dataset\n",
    "    w = [1, 1]\n",
    "    tp_d = paired_pred_type.shape[0]\n",
    "    fp_d = unpaired_pred_type.shape[0]\n",
    "    fn_d = unpaired_true_type.shape[0]\n",
    "\n",
    "    tp_tn_dt = (paired_pred_type == paired_true_type).sum()\n",
    "    fp_fn_dt = (paired_pred_type != paired_true_type).sum()\n",
    "\n",
    "    if not exhaustive:\n",
    "        ignore = (paired_true_type == -1).sum()\n",
    "        fp_fn_dt -= ignore\n",
    "\n",
    "    acc_type = tp_tn_dt / (tp_tn_dt + fp_fn_dt)\n",
    "    f1_d = 2 * tp_d / (2 * tp_d + w[0] * fp_d + w[1] * fn_d)\n",
    "\n",
    "    w = [2, 2, 1, 1]\n",
    "\n",
    "    if type_uid_list is None:\n",
    "        type_uid_list = np.unique(true_inst_type_all).tolist()\n",
    "\n",
    "    results_list = [f1_d, acc_type]\n",
    "    for type_uid in type_uid_list:\n",
    "        f1_type = _f1_type(\n",
    "            paired_true_type,\n",
    "            paired_pred_type,\n",
    "            unpaired_true_type,\n",
    "            unpaired_pred_type,\n",
    "            type_uid,\n",
    "            w,\n",
    "        )\n",
    "        results_list.append(f1_type)\n",
    "\n",
    "    np.set_printoptions(formatter={\"float\": \"{: 0.5f}\".format})\n",
    "    print(np.array(results_list))\n",
    "    return\n",
    "\n",
    "\n",
    "def run_nuclei_inst_stat(pred_dir, true_dir, print_img_stats=False, ext=\".mat\"):\n",
    "    # print stats of each image\n",
    "    print(pred_dir)\n",
    "\n",
    "    file_list = glob.glob(\"%s/*%s\" % (pred_dir, ext))\n",
    "    file_list.sort()  # ensure same order\n",
    "\n",
    "    metrics = [[], [], [], [], [], []]\n",
    "    for filename in file_list[:]:\n",
    "        filename = os.path.basename(filename)\n",
    "        basename = filename.split(\".\")[0]\n",
    "        \n",
    "        true = sio.loadmat(os.path.join(true_dir, basename + \".mat\"))\n",
    "        true = (true[\"inst_map\"]).astype(\"int32\")\n",
    "\n",
    "        pred = sio.loadmat(os.path.join(pred_dir, basename + \".mat\"))\n",
    "        pred = (pred[\"inst_map\"]).astype(\"int32\")\n",
    "\n",
    "        # to ensure that the instance numbering is contiguous\n",
    "        pred = remap_label(pred, by_size=False)\n",
    "        true = remap_label(true, by_size=False)\n",
    "        try:\n",
    "            pq_info = get_fast_pq(true, pred, match_iou=0.5)[0]\n",
    "            dice = get_dice_1(true, pred)\n",
    "            aji = get_fast_aji(true, pred)\n",
    "            aji_plus = get_fast_aji_plus(true, pred)\n",
    "            metrics[0].append(dice)\n",
    "            metrics[1].append(aji)\n",
    "            metrics[2].append(pq_info[0])  # dq\n",
    "            metrics[3].append(pq_info[1])  # sq\n",
    "            metrics[4].append(pq_info[2])  # pq\n",
    "            metrics[5].append(aji_plus)\n",
    "        except:\n",
    "            #print(\"did not run for\", filename)\n",
    "            continue\n",
    "\n",
    "        if print_img_stats:\n",
    "            print(basename, end=\"\\t\")\n",
    "            for scores in metrics:\n",
    "                print(\"%f \" % scores[-1], end=\"  \")\n",
    "            print()\n",
    "    ####\n",
    "    metrics = np.array(metrics)\n",
    "    print(metrics.shape)\n",
    "    print(metrics)\n",
    "    metrics_avg = np.mean(metrics, axis=-1)\n",
    "    np.set_printoptions(formatter={\"float\": \"{: 0.5f}\".format})\n",
    "    print(metrics_avg)\n",
    "    metrics_avg = list(metrics_avg)\n",
    "    return metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a344fc",
   "metadata": {},
   "source": [
    "# CoNSeP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dc8ad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_output\\mat\n",
      "[ 0.84817  0.54631  0.66803  0.77078  0.51617  0.57440]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    true_dir = r'DATA\\CoNSeP\\Test\\Labels'\n",
    "    pred_dir = r\"test_output\\mat\"\n",
    "    \n",
    "    mode = \"instance\";\n",
    "    if mode == \"instance\":\n",
    "        run_nuclei_inst_stat(pred_dir, true_dir, print_img_stats=False)\n",
    "    if mode == \"type\":\n",
    "        run_nuclei_type_stat(pred_dir, true_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410720af",
   "metadata": {},
   "source": [
    "# PanNuke "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4167a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_output\\PanNuke\\mat\n",
      "did not run for 1001.mat\n",
      "did not run for 1006.mat\n",
      "did not run for 1148.mat\n",
      "did not run for 1149.mat\n",
      "did not run for 1150.mat\n",
      "did not run for 1153.mat\n",
      "did not run for 1155.mat\n",
      "did not run for 1156.mat\n",
      "did not run for 1159.mat\n",
      "did not run for 1161.mat\n",
      "did not run for 1162.mat\n",
      "did not run for 1165.mat\n",
      "did not run for 1167.mat\n",
      "did not run for 1433.mat\n",
      "did not run for 1434.mat\n",
      "did not run for 1513.mat\n",
      "did not run for 1615.mat\n",
      "did not run for 1617.mat\n",
      "did not run for 1618.mat\n",
      "did not run for 1619.mat\n",
      "did not run for 1620.mat\n",
      "did not run for 1621.mat\n",
      "did not run for 1705.mat\n",
      "did not run for 1706.mat\n",
      "did not run for 1708.mat\n",
      "did not run for 1709.mat\n",
      "did not run for 1710.mat\n",
      "did not run for 1724.mat\n",
      "did not run for 1725.mat\n",
      "did not run for 1726.mat\n",
      "did not run for 1749.mat\n",
      "did not run for 1750.mat\n",
      "did not run for 1751.mat\n",
      "did not run for 1752.mat\n",
      "did not run for 1753.mat\n",
      "did not run for 1860.mat\n",
      "did not run for 1881.mat\n",
      "did not run for 1924.mat\n",
      "did not run for 1940.mat\n",
      "did not run for 1941.mat\n",
      "did not run for 1946.mat\n",
      "did not run for 1947.mat\n",
      "did not run for 1967.mat\n",
      "did not run for 1968.mat\n",
      "did not run for 1969.mat\n",
      "did not run for 1970.mat\n",
      "did not run for 1971.mat\n",
      "did not run for 1972.mat\n",
      "did not run for 1973.mat\n",
      "did not run for 1974.mat\n",
      "did not run for 1975.mat\n",
      "did not run for 1976.mat\n",
      "did not run for 1977.mat\n",
      "did not run for 1978.mat\n",
      "did not run for 1979.mat\n",
      "did not run for 1980.mat\n",
      "did not run for 2010.mat\n",
      "did not run for 2020.mat\n",
      "did not run for 2021.mat\n",
      "did not run for 2023.mat\n",
      "did not run for 2099.mat\n",
      "did not run for 2112.mat\n",
      "did not run for 2116.mat\n",
      "did not run for 2132.mat\n",
      "did not run for 2133.mat\n",
      "did not run for 2134.mat\n",
      "did not run for 2135.mat\n",
      "did not run for 2136.mat\n",
      "did not run for 2164.mat\n",
      "did not run for 2165.mat\n",
      "did not run for 2166.mat\n",
      "did not run for 2177.mat\n",
      "did not run for 2203.mat\n",
      "did not run for 2264.mat\n",
      "did not run for 2265.mat\n",
      "did not run for 2266.mat\n",
      "did not run for 2268.mat\n",
      "did not run for 2407.mat\n",
      "did not run for 2408.mat\n",
      "did not run for 2409.mat\n",
      "did not run for 2464.mat\n",
      "did not run for 2465.mat\n",
      "did not run for 2551.mat\n",
      "did not run for 2552.mat\n",
      "did not run for 2553.mat\n",
      "did not run for 2627.mat\n",
      "did not run for 2632.mat\n",
      "did not run for 2637.mat\n",
      "did not run for 2638.mat\n",
      "did not run for 2640.mat\n",
      "did not run for 2641.mat\n",
      "did not run for 585.mat\n",
      "did not run for 587.mat\n",
      "did not run for 605.mat\n",
      "did not run for 749.mat\n",
      "did not run for 751.mat\n",
      "did not run for 753.mat\n",
      "did not run for 781.mat\n",
      "did not run for 812.mat\n",
      "did not run for 813.mat\n",
      "did not run for 814.mat\n",
      "did not run for 829.mat\n",
      "did not run for 831.mat\n",
      "did not run for 834.mat\n",
      "(6, 2550)\n",
      "[[0.76881387 0.79649837 0.79486998 ... 0.         0.73553719 0.        ]\n",
      " [0.58809787 0.54829832 0.61531418 ... 0.         0.58169935 0.        ]\n",
      " [0.6        0.61538462 0.68571429 ... 0.         0.66666667 0.        ]\n",
      " [0.8370723  0.76021556 0.80691431 ... 0.         0.91048502 0.        ]\n",
      " [0.50224338 0.46782496 0.55331267 ... 0.         0.60699002 0.        ]\n",
      " [0.58809787 0.56286733 0.61531418 ... 0.         0.58169935 0.        ]]\n",
      "[ 0.83707  0.67175  0.77512  0.81567  0.64081  0.68456]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    true_dir = r'dataset\\PanNuke\\Fold 1\\masks\\fold1\\consep_format'\n",
    "    pred_dir = r\"test_output\\PanNuke\\mat\"\n",
    "    \n",
    "    mode = \"instance\";\n",
    "    if mode == \"instance\":\n",
    "        run_nuclei_inst_stat(pred_dir, true_dir, print_img_stats=False)\n",
    "    if mode == \"type\":\n",
    "        run_nuclei_type_stat(pred_dir, true_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc067274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
